{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://lajavaness.medium.com/1-token-classification-vs-span-categorization-52a685e4674a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/Users/daniel/Projects/Smaragd/sk-llm-01')\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer, BertConfig, get_scheduler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import fact_extraction_model.model.bert_multilabel_classification as model_multilabel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_MODEL = \"./serialized_models/medbert_512/\"\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "BATCH_SIZE = 24\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 1e-2\n",
    "NUM_EPOCHS = 100\n",
    "OUTPUT_DIR = \"./serialized_models/medbert_pretrained_multilabel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'PER', 2: 'ORG', 3: 'LOC', 4: 'MISC', 5: 'NCHUNK', 6: 'TIME', 7: 'PLACE'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use method from shared-python\n",
    "tag2id = {'PER': 1, 'ORG': 2, 'LOC': 3, 'MISC': 4, 'NCHUNK': 5, 'TIME': 6, 'PLACE': 7}\n",
    "id2tag = {v:k for k, v in tag2id.items()}\n",
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 3: 'B-ORG',\n",
       " 5: 'B-LOC',\n",
       " 7: 'B-MISC',\n",
       " 9: 'B-NCHUNK',\n",
       " 11: 'B-TIME',\n",
       " 13: 'B-PLACE',\n",
       " 2: 'I-PER',\n",
       " 4: 'I-ORG',\n",
       " 6: 'I-LOC',\n",
       " 8: 'I-MISC',\n",
       " 10: 'I-NCHUNK',\n",
       " 12: 'I-TIME',\n",
       " 14: 'I-PLACE'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {\n",
    "    'O': 0, \n",
    "    **{f'B-{k}': 2*v - 1 for k, v in tag2id.items()},\n",
    "    **{f'I-{k}': 2*v for k, v in tag2id.items()}\n",
    "}\n",
    "\n",
    "id2label = {v:k for k, v in label2id.items()}\n",
    "NUM_LABELS = len(id2label)\n",
    "id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/daniel/.cache/huggingface/datasets/json/default-068eea7cbca3671a/0.0.0)\n",
      "Found cached dataset json (/Users/daniel/.cache/huggingface/datasets/json/default-5134848318b7c314/0.0.0)\n",
      "Found cached dataset json (/Users/daniel/.cache/huggingface/datasets/json/default-a7132faaa4d75491/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset.from_json(\"./data/multilabel.train.jsonlines\")\n",
    "val_ds = Dataset.from_json(\"./data/multilabel.validation.jsonlines\")\n",
    "test_ds = Dataset.from_json(\"./data/multilabel.test.jsonlines\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader_cas = CASLoader(ANNOTATED_REPORTS_PATH)\n",
    "#train_dict = loader_cas.load_CAS_convert_to_offset_dict()\n",
    "#train_ds = Dataset.from_pandas(pd.DataFrame(data=train_dict))\n",
    "#train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selon l'ethnologue Maurice Duval, « dire que ce mouvement de la gauche radicale est « une secte », ce n'est pas argumenter légitimement contre ses idées, mais c'est suggérer qu'il est malfaisant, malsain et que sa disparition serait souhaitable ».\n",
      "PER        - Maurice Duval\n",
      "NCHUNK     - l'ethnologue Maurice Duval\n",
      "NCHUNK     - ses idées\n",
      "NCHUNK     - sa disparition\n",
      "NCHUNK     - ce mouvement de la gauche radicale\n",
      "\n",
      "Adolescent, il joue de la basse dans un groupe de surf music, commence à composer et s'intéresse aux œuvres de musique contemporaine de compositeurs comme Charles Ives, Karlheinz Stockhausen, Mauricio Kagel, ou encore John Cage.\n",
      "PER        - Charles Ives\n",
      "PER        - Karlheinz Stockhausen\n",
      "PER        - Mauricio Kagel\n",
      "PER        - John Cage\n",
      "NCHUNK     - un groupe de surf music\n",
      "NCHUNK     - œuvres de musique contemporaine de compositeurs comme Charles Ives, Karlheinz Stockhausen, Mauricio Kagel, ou encore John Cage\n",
      "\n",
      "Metacritic \", qui détermine une moyenne pondérée entre 0 et 100 basée sur les critiques populaires, a donné un score moyen de 50 % pour le film, basé sur 40 critiques.\n",
      "MISC       - Metacritic\n",
      "NCHUNK     - une moyenne pondérée entre 0 et 100\n",
      "NCHUNK     - les critiques populaires\n",
      "NCHUNK     - un score moyen de 50 %\n",
      "NCHUNK     - 40 critiques\n"
     ]
    }
   ],
   "source": [
    "def print_examples(): \n",
    "    for i in range(3):\n",
    "        example = train_ds[i]\n",
    "        print(f\"\\n{example['text']}\")\n",
    "        for tag_item in example[\"tags\"]:\n",
    "            print(tag_item[\"tag\"].ljust(10), \"-\", example[\"text\"][tag_item[\"start\"]: tag_item[\"end\"]])\n",
    "\n",
    "print_examples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_role_in_span(token_start: int, token_end: int, span_start: int, span_end: int):\n",
    "    \"\"\"\n",
    "    Check if the token is inside a span.\n",
    "    Args:\n",
    "      - token_start, token_end: Start and end offset of the token\n",
    "      - span_start, span_end: Start and end of the span\n",
    "    Returns:\n",
    "      - \"B\" if beginning\n",
    "      - \"I\" if inner\n",
    "      - \"O\" if outer\n",
    "      - \"N\" if not valid token (like <SEP>, <CLS>, <UNK>)\n",
    "    \"\"\"\n",
    "    if token_end <= token_start:\n",
    "        return \"N\"\n",
    "    if token_start < span_start or token_end > span_end:\n",
    "        return \"O\"\n",
    "    if token_start > span_start:\n",
    "        return \"I\"\n",
    "    else:\n",
    "        return \"B\"\n",
    "\n",
    "def tokenize_and_adjust_labels(sample):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - sample (dict): {\"id\": \"...\", \"text\": \"...\", \"tags\": [{\"start\": ..., \"end\": ..., \"tag\": ...}, ...]\n",
    "    Returns:\n",
    "        - The tokenized version of `sample` and the labels of each token.\n",
    "    \"\"\"\n",
    "    # Tokenize the text, keep the start and end positions of tokens with `return_offsets_mapping` option\n",
    "    # Use max_length and truncation to ajust the text length\n",
    "    tokenized = tokenizer(sample[\"text\"], \n",
    "                          return_offsets_mapping=True, \n",
    "                          padding=\"max_length\", \n",
    "                          max_length=MAX_LENGTH,\n",
    "                          truncation=True)\n",
    "    \n",
    "    # We are doing a multilabel classification task at each token, we create a list of size len(label2id)=13 \n",
    "    # for the 13 labels\n",
    "    labels = [[0 for _ in label2id.keys()] for _ in range(MAX_LENGTH)]\n",
    "    \n",
    "    # Scan all the tokens and spans, assign 1 to the corresponding label if the token lies at the beginning\n",
    "    # or inside the spans\n",
    "    for (token_start, token_end), token_labels in zip(tokenized[\"offset_mapping\"], labels):\n",
    "        for span in sample[\"tags\"]:\n",
    "            role = get_token_role_in_span(token_start, token_end, span[\"start\"], span[\"end\"])\n",
    "            if role == \"B\":\n",
    "                token_labels[label2id[f\"B-{span['tag']}\"]] = 1\n",
    "            elif role == \"I\":\n",
    "                token_labels[label2id[f\"I-{span['tag']}\"]] = 1\n",
    "    \n",
    "    return {**tokenized, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de6740e34c54cc2be6466551ba85c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/329 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957150111c574317a273e0419c6cd0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662f25d9c124bb0843e2d9836a6c4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_ds = train_ds.map(tokenize_and_adjust_labels, remove_columns=train_ds.column_names)\n",
    "tokenized_val_ds = val_ds.map(tokenize_and_adjust_labels, remove_columns=val_ds.column_names)\n",
    "tokenized_test_ds = test_ds.map(tokenize_and_adjust_labels, remove_columns=val_ds.column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2,\n",
       "  6909,\n",
       "  4668,\n",
       "  80,\n",
       "  11,\n",
       "  13613,\n",
       "  5047,\n",
       "  26907,\n",
       "  13041,\n",
       "  5936,\n",
       "  4684,\n",
       "  10420,\n",
       "  7174,\n",
       "  6143,\n",
       "  16,\n",
       "  109,\n",
       "  8633,\n",
       "  7627,\n",
       "  3528,\n",
       "  71,\n",
       "  3528,\n",
       "  16741,\n",
       "  9574,\n",
       "  6219,\n",
       "  5103,\n",
       "  27365,\n",
       "  75,\n",
       "  5408,\n",
       "  3528,\n",
       "  7330,\n",
       "  9816,\n",
       "  3528,\n",
       "  5148,\n",
       "  3533,\n",
       "  109,\n",
       "  4990,\n",
       "  3528,\n",
       "  18432,\n",
       "  4675,\n",
       "  124,\n",
       "  16,\n",
       "  71,\n",
       "  3528,\n",
       "  82,\n",
       "  11,\n",
       "  5148,\n",
       "  3533,\n",
       "  17654,\n",
       "  5626,\n",
       "  7209,\n",
       "  8591,\n",
       "  3536,\n",
       "  80,\n",
       "  3589,\n",
       "  11030,\n",
       "  6110,\n",
       "  6219,\n",
       "  29521,\n",
       "  4741,\n",
       "  10810,\n",
       "  3526,\n",
       "  77,\n",
       "  3540,\n",
       "  3589,\n",
       "  4672,\n",
       "  16,\n",
       "  5715,\n",
       "  4677,\n",
       "  71,\n",
       "  11,\n",
       "  5148,\n",
       "  3533,\n",
       "  5732,\n",
       "  3541,\n",
       "  3541,\n",
       "  3589,\n",
       "  4741,\n",
       "  3536,\n",
       "  7627,\n",
       "  11,\n",
       "  77,\n",
       "  3522,\n",
       "  5148,\n",
       "  3533,\n",
       "  5622,\n",
       "  23460,\n",
       "  4677,\n",
       "  5008,\n",
       "  16,\n",
       "  5622,\n",
       "  22885,\n",
       "  4665,\n",
       "  5124,\n",
       "  7627,\n",
       "  3528,\n",
       "  25266,\n",
       "  11617,\n",
       "  8609,\n",
       "  7315,\n",
       "  10948,\n",
       "  3527,\n",
       "  4682,\n",
       "  4809,\n",
       "  15914,\n",
       "  3527,\n",
       "  29601,\n",
       "  14464,\n",
       "  124,\n",
       "  18,\n",
       "  3],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'offset_mapping': [[0, 0],\n",
       "  [0, 3],\n",
       "  [3, 5],\n",
       "  [6, 7],\n",
       "  [7, 8],\n",
       "  [8, 11],\n",
       "  [11, 13],\n",
       "  [13, 16],\n",
       "  [16, 18],\n",
       "  [19, 21],\n",
       "  [21, 23],\n",
       "  [23, 26],\n",
       "  [27, 29],\n",
       "  [29, 32],\n",
       "  [32, 33],\n",
       "  [34, 35],\n",
       "  [36, 40],\n",
       "  [41, 43],\n",
       "  [43, 44],\n",
       "  [45, 46],\n",
       "  [46, 47],\n",
       "  [48, 50],\n",
       "  [50, 52],\n",
       "  [52, 57],\n",
       "  [58, 60],\n",
       "  [61, 63],\n",
       "  [64, 65],\n",
       "  [65, 69],\n",
       "  [69, 70],\n",
       "  [71, 75],\n",
       "  [75, 78],\n",
       "  [78, 79],\n",
       "  [80, 82],\n",
       "  [82, 83],\n",
       "  [84, 85],\n",
       "  [86, 88],\n",
       "  [88, 89],\n",
       "  [90, 93],\n",
       "  [93, 95],\n",
       "  [96, 97],\n",
       "  [97, 98],\n",
       "  [99, 100],\n",
       "  [100, 101],\n",
       "  [102, 103],\n",
       "  [103, 104],\n",
       "  [104, 106],\n",
       "  [106, 107],\n",
       "  [108, 111],\n",
       "  [112, 114],\n",
       "  [114, 116],\n",
       "  [116, 121],\n",
       "  [121, 122],\n",
       "  [123, 124],\n",
       "  [124, 125],\n",
       "  [125, 127],\n",
       "  [127, 130],\n",
       "  [130, 135],\n",
       "  [136, 140],\n",
       "  [140, 142],\n",
       "  [143, 145],\n",
       "  [145, 146],\n",
       "  [147, 148],\n",
       "  [148, 149],\n",
       "  [149, 150],\n",
       "  [150, 152],\n",
       "  [152, 153],\n",
       "  [154, 156],\n",
       "  [156, 158],\n",
       "  [159, 160],\n",
       "  [160, 161],\n",
       "  [161, 163],\n",
       "  [163, 164],\n",
       "  [165, 167],\n",
       "  [167, 168],\n",
       "  [168, 169],\n",
       "  [169, 170],\n",
       "  [170, 172],\n",
       "  [172, 173],\n",
       "  [174, 176],\n",
       "  [176, 177],\n",
       "  [177, 178],\n",
       "  [178, 179],\n",
       "  [180, 182],\n",
       "  [182, 183],\n",
       "  [184, 187],\n",
       "  [187, 189],\n",
       "  [189, 191],\n",
       "  [191, 194],\n",
       "  [194, 195],\n",
       "  [196, 199],\n",
       "  [199, 201],\n",
       "  [201, 203],\n",
       "  [204, 206],\n",
       "  [207, 209],\n",
       "  [209, 210],\n",
       "  [211, 213],\n",
       "  [214, 217],\n",
       "  [217, 220],\n",
       "  [220, 225],\n",
       "  [226, 229],\n",
       "  [229, 230],\n",
       "  [230, 232],\n",
       "  [233, 235],\n",
       "  [235, 237],\n",
       "  [237, 238],\n",
       "  [238, 241],\n",
       "  [241, 244],\n",
       "  [245, 246],\n",
       "  [246, 247],\n",
       "  [0, 0]],\n",
       " 'labels': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Token---------|--------Labels----------\n",
      " [CLS]                | []\n",
      " Les                  | ['B-NCHUNK']\n",
      " part                 | ['I-NCHUNK']\n",
      " ##ies                | ['I-NCHUNK']\n",
      " pr                   | ['I-NCHUNK']\n",
      " ##é                  | ['I-NCHUNK']\n",
      " ##f                  | ['I-NCHUNK']\n",
      " ##é                  | ['I-NCHUNK']\n",
      " ##r                  | ['I-NCHUNK']\n",
      " ##é                  | ['I-NCHUNK']\n",
      " ##es                 | ['I-NCHUNK']\n",
      " son                  | []\n",
      " ##t                  | []\n",
      " les                  | []\n",
      " p                    | []\n",
      " ##in                 | []\n",
      " ##ces                | []\n",
      " et                   | []\n",
      " les                  | []\n",
      " pa                   | []\n",
      " ##tt                 | []\n",
      " ##es                 | []\n",
      " ,                    | []\n",
      " bie                  | []\n",
      " ##n                  | []\n",
      " qu                   | []\n",
      " ##e                  | []\n",
      " les                  | []\n",
      " œ                    | []\n",
      " ##uf                 | []\n",
      " ##s                  | []\n",
      " et                   | []\n",
      " le                   | ['B-NCHUNK']\n",
      " gra                  | ['I-NCHUNK']\n",
      " ##s                  | ['I-NCHUNK']\n",
      " de                   | ['I-NCHUNK']\n",
      " l                    | ['I-NCHUNK']\n",
      " '                    | ['I-NCHUNK']\n",
      " abd                  | ['I-NCHUNK']\n",
      " ##omen               | ['I-NCHUNK']\n",
      " et                   | []\n",
      " da                   | ['B-PLACE']\n",
      " ##ns                 | ['I-PLACE']\n",
      " les                  | ['I-PLACE']\n",
      " Tu                   | ['B-LOC', 'I-PLACE']\n",
      " ##am                 | ['I-LOC', 'I-PLACE']\n",
      " ##ot                 | ['I-LOC', 'I-PLACE']\n",
      " ##u                  | ['I-LOC', 'I-PLACE']\n",
      " (                    | []\n",
      " en                   | ['B-PLACE']\n",
      " Poly                 | ['B-LOC', 'I-PLACE']\n",
      " ##n                  | ['I-LOC', 'I-PLACE']\n",
      " ##é                  | ['I-LOC', 'I-PLACE']\n",
      " ##sie                | ['I-LOC', 'I-PLACE']\n",
      " fra                  | ['I-LOC', 'I-PLACE']\n",
      " ##n                  | ['I-LOC', 'I-PLACE']\n",
      " ##ç                  | ['I-LOC', 'I-PLACE']\n",
      " ##a                  | ['I-LOC', 'I-PLACE']\n",
      " ##ise                | ['I-LOC', 'I-PLACE']\n",
      " )                    | []\n",
      " ,                    | []\n",
      " mi                   | []\n",
      " ##s                  | []\n",
      " sur                  | []\n",
      " le                   | ['B-NCHUNK']\n",
      " comp                 | ['I-NCHUNK']\n",
      " ##te                 | ['I-NCHUNK']\n",
      " de                   | ['I-NCHUNK']\n",
      " la                   | ['I-NCHUNK']\n",
      " con                  | ['I-NCHUNK']\n",
      " ##so                 | ['I-NCHUNK']\n",
      " ##mm                 | ['I-NCHUNK']\n",
      " ##ation              | ['I-NCHUNK']\n",
      " par                  | ['I-NCHUNK']\n",
      " l                    | ['I-NCHUNK']\n",
      " '                    | ['I-NCHUNK']\n",
      " an                   | ['I-NCHUNK']\n",
      " ##imal               | ['I-NCHUNK']\n",
      " de                   | []\n",
      " c                    | []\n",
      " ##ert                | []\n",
      " ##ain                | []\n",
      " ##s                  | []\n",
      " v                    | []\n",
      " ##é                  | []\n",
      " ##g                  | []\n",
      " ##é                  | []\n",
      " ##ta                 | []\n",
      " ##ux                 | []\n",
      " .                    | []\n",
      " [SEP]                | []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = tokenized_test_ds[0]\n",
    "\n",
    "print(\"--------Token---------|--------Labels----------\")\n",
    "for token_id, token_labels in zip(sample[\"input_ids\"], sample[\"labels\"]):\n",
    "    # Decode the token_id into text\n",
    "    token_text = tokenizer.decode(token_id)\n",
    "    \n",
    "    # Retrieve all the indices corresponding to the \"1\" at each token, decode them to label name\n",
    "    labels = [id2label[label_index] for label_index, value in enumerate(token_labels) if value==1]\n",
    "    \n",
    "    # Decode those indices into label name\n",
    "    print(f\" {token_text:20} | {labels}\")\n",
    "    \n",
    "    # Finish when we meet the end of sentence.\n",
    "    if token_text == \"</s>\": \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_collator = DataCollatorWithPadding(tokenizer, padding=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Native pytorch code below\n",
    "train_dl = DataLoader(\n",
    "    tokenized_train_ds,\n",
    "    shuffle=True,\n",
    "    # sampler=SubsetRandomSampler(np.random.randint(0, encoded_gmb_dataset[\"train\"].num_rows, 1000).tolist()),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "valid_dl = DataLoader(\n",
    "    tokenized_val_ds,\n",
    "    shuffle=False,\n",
    "    # sampler=SubsetRandomSampler(np.random.randint(0, encoded_gmb_dataset[\"validation\"].num_rows, 200).tolist()),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    tokenized_test_ds,\n",
    "    shuffle=False,\n",
    "    #  sampler=SubsetRandomSampler(np.random.randint(0, encoded_gmb_dataset[\"test\"].num_rows, 100).tolist()),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at ./serialized_models/medbert_512/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model instantiation\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "config = BertConfig.from_pretrained(BASE_MODEL)\n",
    "\n",
    "model = model_multilabel.BertForMultiLabelClassification.from_pretrained(\n",
    "    BASE_MODEL, num_labels=NUM_LABELS, label2id=label2id, id2label=id2label\n",
    ")\n",
    "\n",
    "\n",
    "# Resize embedding size if additional tokens are added (only for RE)\n",
    "# model.bert.resize_token_embeddings(len(tokenizer.vocab))\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "num_training_steps = NUM_EPOCHS * len(train_dl)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a: int, b: int):\n",
    "    return a / b if b > 0 else 0\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Customize the `compute_metrics` of `transformers`\n",
    "    Args:\n",
    "        - p (tuple):      2 numpy arrays: predictions and true_labels\n",
    "    Returns:\n",
    "        - metrics (dict): f1 score on \n",
    "    \"\"\"\n",
    "    # (1)\n",
    "    predictions, true_labels = p\n",
    "    \n",
    "    # (2)\n",
    "    predicted_labels = np.where(predictions > 0, np.ones(predictions.shape), np.zeros(predictions.shape))\n",
    "    metrics = {}\n",
    "    \n",
    "    # (3)\n",
    "    cm = multilabel_confusion_matrix(true_labels.reshape(-1, NUM_LABELS), predicted_labels.reshape(-1, NUM_LABELS))\n",
    "    \n",
    "    # (4) \n",
    "    for label_idx, matrix in enumerate(cm):\n",
    "        if label_idx == 0:\n",
    "            continue # We don't care about the label \"O\"\n",
    "        tp, fp, fn = matrix[1, 1], matrix[0, 1], matrix[1, 0]\n",
    "        precision = divide(tp, tp + fp)\n",
    "        recall = divide(tp, tp + fn)\n",
    "        f1 = divide(2 * precision * recall, precision + recall)\n",
    "        metrics[f\"f1_{id2label[label_idx]}\"] = f1\n",
    "        \n",
    "    # (5)\n",
    "    macro_f1 = sum(list(metrics.values())) / (NUM_LABELS - 1)\n",
    "    metrics[\"macro_f1\"] = macro_f1\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(model, train_dl):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for bid, batch in enumerate(train_dl):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.detach().cpu().numpy()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def do_eval(model, eval_dl):\n",
    "    model.eval()\n",
    "    eval_loss, eval_score, num_batches = 0, 0, 0\n",
    "    for bid, batch in enumerate(eval_dl):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        eval_loss += loss.detach().cpu().numpy()\n",
    "        #eval_score += compute_f1_score(batch[\"labels\"], outputs.logits)\n",
    "        metrics = compute_metrics([outputs.logits.cpu(),batch[\"labels\"].cpu()])\n",
    "        eval_score +=metrics[\"macro_f1\"]\n",
    "        num_batches += 1\n",
    "\n",
    "    eval_score /= num_batches\n",
    "\n",
    "    return eval_loss, eval_score\n",
    "\n",
    "\n",
    "def save_checkpoint(model, model_dir, epoch):\n",
    "    model.save_pretrained(os.path.join(OUTPUT_DIR, \"ckpt-{:d}\".format(epoch)))\n",
    "\n",
    "\n",
    "def save_training_history(history, model_dir, epoch):\n",
    "    fhist = open(os.path.join(OUTPUT_DIR, \"history.tsv\"), \"w\")\n",
    "    for epoch, train_loss, eval_loss, eval_score in history:\n",
    "        fhist.write(\n",
    "            \"{:d}\\t{:.5f}\\t{:.5f}\\t{:.5f}\\n\".format(\n",
    "                epoch, train_loss, eval_loss, eval_score\n",
    "            )\n",
    "        )\n",
    "    fhist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`offset_mapping` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:731\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 731\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[1;32m    733\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 30 at dim 1 (got 108)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m history \u001b[39m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 10\u001b[0m     train_loss \u001b[39m=\u001b[39m do_train(model, train_dl)\n\u001b[1;32m     11\u001b[0m     eval_loss, eval_score \u001b[39m=\u001b[39m do_eval(model, valid_dl)\n\u001b[1;32m     12\u001b[0m     history\u001b[39m.\u001b[39mappend((epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, train_loss, eval_loss, eval_score))\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mdo_train\u001b[0;34m(model, train_dl)\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m bid, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dl):\n\u001b[1;32m      5\u001b[0m     batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      6\u001b[0m     outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/data/data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 249\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(\n\u001b[1;32m    250\u001b[0m         features,\n\u001b[1;32m    251\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    252\u001b[0m         max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[1;32m    253\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m    254\u001b[0m         return_tensors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_tensors,\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m    257\u001b[0m         batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3074\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3071\u001b[0m             batch_outputs[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m   3072\u001b[0m         batch_outputs[key]\u001b[39m.\u001b[39mappend(value)\n\u001b[0;32m-> 3074\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(batch_outputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:211\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    207\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:747\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    744\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    746\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    750\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m features (`\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    752\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`offset_mapping` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "#if os.path.exists(OUTPUT_DIR):\n",
    " #   shutil.rmtree(OUTPUT_DIR)\n",
    " #   os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = do_train(model, train_dl)\n",
    "    eval_loss, eval_score = do_eval(model, valid_dl)\n",
    "    history.append((epoch + 1, train_loss, eval_loss, eval_score))\n",
    "    print(\n",
    "        \"EPOCH {:d}, train loss: {:.3f}, val loss: {:.3f}, f1-score: {:.5f}\".format(\n",
    "            epoch + 1, train_loss, eval_loss, eval_score\n",
    "        )\n",
    "    )\n",
    "    save_checkpoint(model, OUTPUT_DIR, epoch + 1)\n",
    "    save_training_history(history, OUTPUT_DIR, epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_loss_diagram():\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot([train_loss for _, train_loss, _, _ in history], label=\"train\")\n",
    "    plt.plot([eval_loss for _, _, eval_loss, _ in history], label=\"validation\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot([eval_score for _, _, _, eval_score in history], label=\"validation\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"f1-score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR + \"/loss.png\", dpi=300)\n",
    "\n",
    "\n",
    "make_loss_diagram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "./serialized_models/medbert_pretrained_multilabel does not appear to have a file named config.json. Checkout 'https://huggingface.co/./serialized_models/medbert_pretrained_multilabel/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m model_multilabel\u001b[39m.\u001b[39;49mBertForMultiLabelClassification\u001b[39m.\u001b[39;49mfrom_pretrained(OUTPUT_DIR)\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(BASE_MODEL)\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:2325\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2324\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2325\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   2326\u001b[0m         config_path,\n\u001b[1;32m   2327\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2328\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2329\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2330\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2331\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2332\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2333\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2334\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2335\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2336\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   2337\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   2338\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2339\u001b[0m     )\n\u001b[1;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:590\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mrevision\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m revision\n\u001b[1;32m    588\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 590\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    592\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    593\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    594\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:617\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    616\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    619\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:672\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m configuration_file \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_configuration_file\u001b[39m\u001b[39m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    670\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    673\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    674\u001b[0m         configuration_file,\n\u001b[1;32m    675\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    676\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    677\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    678\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    679\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    680\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    681\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    682\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    683\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    684\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    687\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Smaragd/sk-llm-01/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:388\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 388\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    389\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named \u001b[39m\u001b[39m{\u001b[39;00mfull_filename\u001b[39m}\u001b[39;00m\u001b[39m. Checkout \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available files.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: ./serialized_models/medbert_pretrained_multilabel does not appear to have a file named config.json. Checkout 'https://huggingface.co/./serialized_models/medbert_pretrained_multilabel/main' for available files."
     ]
    }
   ],
   "source": [
    "model = model_multilabel.BertForMultiLabelClassification.from_pretrained(OUTPUT_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offsets_and_predicted_tags(example: str, model, tokenizer, threshold=0):\n",
    "    \"\"\"\n",
    "    Get prediction of model on example, using tokenizer\n",
    "    Args:\n",
    "      - example (str): The input text\n",
    "      - model: The span categorizer\n",
    "      - tokenizer: The tokenizer\n",
    "      - threshold: The threshold to decide whether the token should belong to the label. Default to 0, which corresponds to probability 0.5.\n",
    "    Returns:\n",
    "      - List of (token, tags, offset) for each token.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentence to retrieve the tokens and offset mappings\n",
    "    raw_encoded_example = tokenizer(example, return_offsets_mapping=True)\n",
    "    encoded_example = tokenizer(example, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Call the model. The output LxK-tensor where L is the number of tokens, K is the number of classes\n",
    "    out = model(**encoded_example)[\"logits\"][0]\n",
    "    \n",
    "    # We assign to each token the classes whose logit is positive\n",
    "    predicted_tags = [[i for i, l in enumerate(logit) if l > threshold] for logit in out]\n",
    "    \n",
    "    return [{\"token\": token, \"tags\": tag, \"offset\": offset} for (token, tag, offset) \n",
    "            in zip(tokenizer.batch_decode(raw_encoded_example[\"input_ids\"]), \n",
    "                   predicted_tags, \n",
    "                   raw_encoded_example[\"offset_mapping\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           - []\n",
      "Du              - []\n",
      "co              - []\n",
      "##up            - []\n",
      ",               - []\n",
      "la              - [9]\n",
      "men             - [10]\n",
      "##ace           - [10]\n",
      "des             - [10]\n",
      "fe              - [10]\n",
      "##ux            - [10]\n",
      "de              - [10]\n",
      "for             - [10]\n",
      "##ê             - []\n",
      "##t             - []\n",
      "es              - []\n",
      "##t             - []\n",
      "perman          - []\n",
      "##ente          - []\n",
      ",               - []\n",
      "ap              - []\n",
      "##r             - []\n",
      "##è             - []\n",
      "##s             - []\n",
      "les             - [9]\n",
      "inc             - [10]\n",
      "##end           - [10]\n",
      "##ies           - [10]\n",
      "d               - [10]\n",
      "##é             - [10]\n",
      "##vas           - [10]\n",
      "##ta            - [10]\n",
      "##teu           - [10]\n",
      "##r             - [10]\n",
      "##s             - [10]\n",
      "de              - [10]\n",
      "ju              - [10]\n",
      "##ille          - [10]\n",
      "##t             - [10]\n",
      "da              - []\n",
      "##ns            - []\n",
      "le              - [9]\n",
      "su              - [10]\n",
      "##d             - [10]\n",
      "-               - [10]\n",
      "o               - [10]\n",
      "##ue            - [10]\n",
      "##st            - [10]\n",
      "de              - [10]\n",
      "la              - []\n",
      "Fran            - [5]\n",
      "##ce            - [6]\n",
      ",               - []\n",
      "en              - [13]\n",
      "Es              - [5, 14]\n",
      "##pa            - [6, 14]\n",
      "##gn            - [6, 14]\n",
      "##e             - [6, 14]\n",
      ",               - []\n",
      "au              - [13]\n",
      "Port            - [5, 14]\n",
      "##ug            - [6, 14]\n",
      "##al            - [6, 14]\n",
      "o               - [6, 14]\n",
      "##u             - [6, 14]\n",
      "en              - [13]\n",
      "Gr              - [5, 14]\n",
      "##è             - [6, 14]\n",
      "##ce            - [6, 14]\n",
      ".               - []\n",
      "Un              - []\n",
      "im              - []\n",
      "##port          - []\n",
      "##ant           - []\n",
      "fe              - []\n",
      "##u             - []\n",
      "de              - []\n",
      "for             - []\n",
      "##ê             - []\n",
      "##t             - []\n",
      "a               - []\n",
      "é               - []\n",
      "##cl            - []\n",
      "##at            - []\n",
      "##é             - []\n",
      "le              - []\n",
      "24              - []\n",
      "ju              - []\n",
      "##ille          - []\n",
      "##t             - []\n",
      "da              - []\n",
      "##ns            - []\n",
      "le              - [9]\n",
      "par             - [10]\n",
      "##c             - [10]\n",
      "nation          - [10]\n",
      "##al            - [10]\n",
      "de              - [10]\n",
      "la              - [10]\n",
      "Su              - [5, 10]\n",
      "##isse          - [6, 10]\n",
      "de              - [6, 10]\n",
      "Bo              - [6, 10]\n",
      "##h             - [6, 10]\n",
      "##ê             - [6, 10]\n",
      "##me            - [6, 10]\n",
      ",               - []\n",
      "à               - []\n",
      "la              - []\n",
      "front           - []\n",
      "##i             - []\n",
      "##è             - []\n",
      "##re            - []\n",
      "ent             - []\n",
      "##re            - []\n",
      "la              - []\n",
      "R               - [5]\n",
      "##é             - [6, 14]\n",
      "##publ          - [6, 14]\n",
      "##iqu           - [6, 14]\n",
      "##e             - [6, 14]\n",
      "t               - [6, 14]\n",
      "##ch            - [6, 14]\n",
      "##è             - [6, 14]\n",
      "##que           - [6, 14]\n",
      "et              - []\n",
      "l               - []\n",
      "'               - []\n",
      "Alle            - [5]\n",
      "##ma            - [6, 14]\n",
      "##gn            - [6, 14]\n",
      "##e             - [6, 14]\n",
      ",               - []\n",
      "o               - []\n",
      "##ù             - []\n",
      "des             - [9]\n",
      "rec             - [10]\n",
      "##ord           - [10]\n",
      "##s             - [10]\n",
      "de              - [10]\n",
      "ch              - [10]\n",
      "##ale           - [10]\n",
      "##ur            - [10]\n",
      "on              - []\n",
      "##t             - []\n",
      "é               - []\n",
      "##t             - []\n",
      "##é             - []\n",
      "b               - []\n",
      "##att           - []\n",
      "##us            - []\n",
      "(               - []\n",
      "36              - []\n",
      ",               - []\n",
      "4               - []\n",
      "##C             - []\n",
      ")               - []\n",
      ".               - []\n",
      "Un              - [9]\n",
      "mil             - [10]\n",
      "##lie           - [10]\n",
      "##r             - [10]\n",
      "d               - [10]\n",
      "'               - [10]\n",
      "he              - [10]\n",
      "##ct            - [10]\n",
      "##ares          - [10]\n",
      "on              - []\n",
      "##t             - []\n",
      "d               - []\n",
      "##é             - []\n",
      "##j             - []\n",
      "##à             - []\n",
      "é               - []\n",
      "##t             - []\n",
      "##é             - []\n",
      "to              - []\n",
      "##uch           - []\n",
      "##é             - []\n",
      "##s             - []\n",
      ".               - []\n",
      "Lun             - [5]\n",
      "##di            - [6]\n",
      ",               - []\n",
      "les             - [9]\n",
      "po              - [10]\n",
      "##mp            - [10]\n",
      "##ier           - [10]\n",
      "##s             - [10]\n",
      "es              - []\n",
      "##p             - []\n",
      "##é             - []\n",
      "##ra            - []\n",
      "##ien           - []\n",
      "##t             - []\n",
      "qu              - []\n",
      "##e             - []\n",
      "l               - []\n",
      "'               - []\n",
      "inc             - []\n",
      "##end           - []\n",
      "##ie            - []\n",
      "po              - []\n",
      "##urr           - []\n",
      "##a             - []\n",
      "##it            - []\n",
      "ê               - []\n",
      "##tre           - []\n",
      "ma              - []\n",
      "##î             - []\n",
      "##tr            - []\n",
      "##is            - []\n",
      "##é             - []\n",
      "en              - []\n",
      "qu              - []\n",
      "##el            - [12]\n",
      "##ques          - [12]\n",
      "j               - [12]\n",
      "##our           - [12]\n",
      "##s             - [12]\n",
      ".               - []\n",
      "[SEP]           - []\n"
     ]
    }
   ],
   "source": [
    "example = \"Du coup, la menace des feux de forêt est permanente, après les incendies dévastateurs de juillet dans le sud-ouest de la France, en Espagne, au Portugal ou en Grèce. Un important feu de forêt a éclaté le 24 juillet dans le parc national de la Suisse de Bohême, à la frontière entre la République tchèque et l'Allemagne, où des records de chaleur ont été battus (36,4C). Un millier d'hectares ont déjà été touchés. Lundi, les pompiers espéraient que l'incendie pourrait être maîtrisé en quelques jours.\"\n",
    "for item in get_offsets_and_predicted_tags(example, model, tokenizer):\n",
    "    print(f\"\"\"{item[\"token\"]:15} - {item[\"tags\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Du coup, la menace des feux de forêt est permanente, après les incendies dévastateurs de juillet dans le sud-ouest de la France, en Espagne, au Portugal ou en Grèce. Un important feu de forêt a éclaté le 24 juillet dans le parc national de la Suisse de Bohême, à la frontière entre la République tchèque et l'Allemagne, où des records de chaleur ont été battus (36,4C). Un millier d'hectares ont déjà été touchés. Lundi, les pompiers espéraient que l'incendie pourrait être maîtrisé en quelques jours.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start': 9, 'end': 34, 'tag': 'NCHUNK', 'text': 'la menace des feux de for'},\n",
       " {'start': 59,\n",
       "  'end': 96,\n",
       "  'tag': 'NCHUNK',\n",
       "  'text': 'les incendies dévastateurs de juillet'},\n",
       " {'start': 102, 'end': 117, 'tag': 'NCHUNK', 'text': 'le sud-ouest de'},\n",
       " {'start': 121, 'end': 127, 'tag': 'LOC', 'text': 'France'},\n",
       " {'start': 129, 'end': 139, 'tag': 'PLACE', 'text': 'en Espagne'},\n",
       " {'start': 132, 'end': 139, 'tag': 'LOC', 'text': 'Espagne'},\n",
       " {'start': 141, 'end': 155, 'tag': 'PLACE', 'text': 'au Portugal ou'},\n",
       " {'start': 144, 'end': 155, 'tag': 'LOC', 'text': 'Portugal ou'},\n",
       " {'start': 156, 'end': 164, 'tag': 'PLACE', 'text': 'en Grèce'},\n",
       " {'start': 159, 'end': 164, 'tag': 'LOC', 'text': 'Grèce'},\n",
       " {'start': 220,\n",
       "  'end': 259,\n",
       "  'tag': 'NCHUNK',\n",
       "  'text': 'le parc national de la Suisse de Bohême'},\n",
       " {'start': 243, 'end': 259, 'tag': 'LOC', 'text': 'Suisse de Bohême'},\n",
       " {'start': 285, 'end': 303, 'tag': 'LOC', 'text': 'République tchèque'},\n",
       " {'start': 286, 'end': 303, 'tag': 'PLACE', 'text': 'épublique tchèque'},\n",
       " {'start': 309, 'end': 318, 'tag': 'LOC', 'text': 'Allemagne'},\n",
       " {'start': 313, 'end': 318, 'tag': 'PLACE', 'text': 'magne'},\n",
       " {'start': 323, 'end': 345, 'tag': 'NCHUNK', 'text': 'des records de chaleur'},\n",
       " {'start': 370, 'end': 391, 'tag': 'NCHUNK', 'text': \"Un millier d'hectares\"},\n",
       " {'start': 414, 'end': 419, 'tag': 'LOC', 'text': 'Lundi'},\n",
       " {'start': 421, 'end': 433, 'tag': 'NCHUNK', 'text': 'les pompiers'},\n",
       " {'start': 488, 'end': 500, 'tag': 'TIME', 'text': 'elques jours'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tagged_groups(example: str, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Get prediction of model on example, using tokenizer\n",
    "    Returns:\n",
    "    - List of spans under offset format {\"start\": ..., \"end\": ..., \"tag\": ...}, sorted by start, end then tag.\n",
    "    \"\"\"\n",
    "    offsets_and_tags = get_offsets_and_predicted_tags(example, model, tokenizer)\n",
    "    predicted_offsets = {l: [] for l in tag2id}\n",
    "    last_token_tags = []\n",
    "    for item in offsets_and_tags:\n",
    "        (start, end), tags = item[\"offset\"], item[\"tags\"]\n",
    "        \n",
    "        for label_id in tags:\n",
    "            label = id2label[label_id]\n",
    "            tag = label[2:] # \"I-PER\" => \"PER\"\n",
    "            if label.startswith(\"B-\"):\n",
    "                predicted_offsets[tag].append({\"start\": start, \"end\": end})\n",
    "            elif label.startswith(\"I-\"):\n",
    "                # If \"B-\" and \"I-\" both appear in the same tag, ignore as we already processed it\n",
    "                if label2id[f\"B-{tag}\"] in tags:\n",
    "                    continue\n",
    "                \n",
    "                if label_id not in last_token_tags and label2id[f\"B-{tag}\"] not in last_token_tags:\n",
    "                    predicted_offsets[tag].append({\"start\": start, \"end\": end})\n",
    "                else:\n",
    "                    predicted_offsets[tag][-1][\"end\"] = end\n",
    "        \n",
    "        last_token_tags = tags\n",
    "        \n",
    "    flatten_predicted_offsets = [{**v, \"tag\": k, \"text\": example[v[\"start\"]:v[\"end\"]]} \n",
    "                                 for k, v_list in predicted_offsets.items() for v in v_list if v[\"end\"] - v[\"start\"] >= 3]\n",
    "    flatten_predicted_offsets = sorted(flatten_predicted_offsets, \n",
    "                                       key = lambda row: (row[\"start\"], row[\"end\"], row[\"tag\"]))\n",
    "    return flatten_predicted_offsets\n",
    "\n",
    "print(example)\n",
    "get_tagged_groups(example, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
