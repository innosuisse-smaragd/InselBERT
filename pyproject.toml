
[project]
name = "llm-model"
version = "0.1"
description = "LLM-based, two-layer clinical fact extraction based on the approach by Steinkamp et al."
authors = [
    {name = "Daniel Reichenpfader", email = "daniel.reichenpfader@bfh.ch"},
]
dependencies = [
    "torch>=2.0.1",
    "transformers>=4.31.0",
    "smaragd-shared-python @ git+https://${GITHUB_ACCESS_TOKEN}@github.com/innosuisse-smaragd/smaragd-shared-python.git@v2.6.0",
    "bentoml[io-json]>=1.0.22",
    "datasets>=2.13.1",
    "seqeval>=1.2.2",
    "matplotlib>=3.7.2",
]
requires-python = ">=3.11"

[tool.pdm.dev-dependencies]
dev = [
    "jupyter>=1.0.0",
    "isort>=5.12.0",
    "pycodestyle>=2.10.0",
    "accelerate>=0.21.0",
    "wandb>=0.15.7",
]

[tool.pdm.scripts] # See: https://pdm.fming.dev/2.7/usage/scripts/
lint = {cmd = "pycodestyle ./src ./test --max-line-length 120"}
# test = {cmd = "pytest"}
check-import-order = {cmd = "isort ./src ./test --check-only"}
fix-import-order = {cmd = "isort ./src ./test"}

run-bento-dev = {cmd = "bentoml serve service:svc --reload"}
build-bento = {cmd = "bentoml build ./src/"}
run-bento = {cmd = "bentoml serve inselbert_extract_f_a:latest"}
containerize-bento = {cmd = "bentoml containerize --opt platform=linux/amd64 inselbert_extract_f_a:latest"}

further-pretrain = {call = "src.further_pre_training.training.exec_training:further_pretrain_model"}
finetune-fact-anchor-model = "python src/fact_extraction_model/training/exec_training.py"
finetune-modifier-model = "python src/refinement_model/training/exec_training.py"
test-inference = "python src/refinement_model/inference/service.py"